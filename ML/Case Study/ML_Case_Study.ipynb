{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b0e72-f601-4b98-9846-9c8caf3c6676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Create a DataFrame with the following e-commerce sales data: \n",
    "# Columns: OrderID, CustomerID, Product, Category, Quantity, Price, OrderDate, Rating, Review \n",
    "# Create at least 50 sample records with realistic data including dates from 2023-2024 \n",
    "# Display the first 10 and last 5 records using head() and tail() \n",
    "\n",
    "# Q2: Use info() and describe() to get a comprehensive overview of the dataset \n",
    "# Identify data types, missing values, and statistical summary \n",
    "# Print the column names using columns attribute and shape of the dataset \n",
    "\n",
    "# Q3: Introduce 10% missing values randomly in Rating and Review columns \n",
    "# Detect missing values and display the count of missing values per column \n",
    "# Fill missing ratings with the median rating and missing reviews with \"No review provided\" \n",
    "\n",
    "# Q4: Create a new column 'TotalAmount' by multiplying Quantity and Price \n",
    "# Add another column 'DiscountedPrice' that applies 10% discount on orders above $100 \n",
    "# Use conditional selection to filter orders where TotalAmount > $150 \n",
    "\n",
    "# Q5: Select only the columns: Product, Category, TotalAmount, and Rating \n",
    "# Filter and display all orders from the 'Electronics' category with Rating >= 4 \n",
    "\n",
    "# Q6: Use boolean indexing to find all orders where: \n",
    "# - Quantity > 2 AND Price < 50 OR Rating == 5 \n",
    "# Display the count of such orders \n",
    "\n",
    "# Q7: Sort the entire DataFrame by OrderDate (descending) and then by TotalAmount (descending) \n",
    "# Create a new column 'SalesRank' that ranks products by TotalAmount in descending order \n",
    "\n",
    "# Q8: Find the top 5 best-selling products based on total quantity sold \n",
    "# Display the product name and total quantity in descending order \n",
    "\n",
    "\n",
    "# PART 5: GROUPING & AGGREGATION (Statistical Analysis) \n",
    "# Q9: Group the data by 'Category' and calculate: \n",
    "# - Total sales (sum of TotalAmount) \n",
    "# - Average rating \n",
    "# - Number of orders \n",
    "# Display the results sorted by total sales \n",
    "\n",
    "# Q10: Create a pivot table showing average Price for each Category and Rating combination \n",
    "# Use groupby with multiple columns (Category, Product) and aggregate multiple functions \n",
    "\n",
    "# Q11: Convert the Quantity and Price columns to NumPy arrays \n",
    "# Create a 2D array combining these two columns \n",
    "# Display array properties: shape, dtype, ndim, size \n",
    "\n",
    "# Q12: Create a 1D NumPy array of 100 random prices between 10 and 500 \n",
    "# Calculate mean, median, standard deviation, min, and max using NumPy functions \n",
    "# Reshape this array into a 10x10 matrix \n",
    "\n",
    "# Q13: Create two 3D NumPy arrays (3x3x3) with random integers \n",
    "# Perform element-wise addition, multiplication, and matrix multiplication \n",
    "# Use boolean indexing to filter values greater than 50 \n",
    "\n",
    "# Q14: Create NumPy arrays using special values: \n",
    "# - Array of zeros (5x5) \n",
    "# - Array of ones (3x4) \n",
    "# - Identity matrix (4x4) \n",
    "# - Array with values from 0 to 50 with step of 5 using arange \n",
    "# Concatenate and stack these arrays \n",
    "\n",
    "# Q15: Use array slicing to extract: \n",
    "# - First 3 rows from the Quantity-Price 2D array \n",
    "# - Every alternate element from the Price array \n",
    "# - Diagonal elements from a 5x5 matrix of TotalAmount values \n",
    "\n",
    "# Q16: Create a correlation matrix between Quantity, Price, Rating, and TotalAmount using NumPy \n",
    "# Calculate the covariance matrix \n",
    "# Perform linear algebra operations: determinant and inverse of correlation matrix \n",
    "\n",
    "# Q17: Generate 1000 random samples from a normal distribution (mean=100, std=15) \n",
    "# Calculate percentiles: 25th, 50th, 75th, 90th, 95th \n",
    "# Demonstrate the difference between copy and view using these arrays \n",
    "\n",
    "# Q18: Create a random array of 1000 sales values \n",
    "# Use NumPy to flatten, reshape into (100, 10), and then transpose \n",
    "# Compare memory usage between original, copy, and view \n",
    "\n",
    "# Q19: Create a line plot showing total sales trend over months \n",
    "# Customize with: title, xlabel, ylabel, grid, legend \n",
    "# Use different line styles, colors, and markers \n",
    "\n",
    "# Q20: Create a bar chart comparing total sales across different categories \n",
    "# Customize colors for each bar and add value labels on top of bars \n",
    "# Create a horizontal bar chart as well \n",
    "\n",
    "# Q21: Create a scatter plot showing relationship between Price and Rating \n",
    "# Color points by Category and vary point size by Quantity \n",
    "# Add a trend line and customize markers \n",
    "\n",
    "# Q22: Create a histogram showing the distribution of TotalAmount \n",
    "# Use 20 bins and customize colors and transparency \n",
    "# Add a vertical line showing the mean value \n",
    "\n",
    "# Q23: Create a pie chart showing percentage distribution of sales by Category \n",
    "# Explode the largest segment and display percentages \n",
    "# Customize colors and add a legend \n",
    "\n",
    "# Q24: Create a 2x2 subplot figure containing: \n",
    "# - Top-left: Sales trend line plot \n",
    "# - Top-right: Category-wise bar chart \n",
    "# - Bottom-left: Rating distribution histogram \n",
    "# - Bottom-right: Sales by category pie chart \n",
    "# Save this dashboard as 'sales_dashboard.png' with 300 dpi \n",
    "\n",
    "# Q25: Create a comprehensive mini-dashboard (3x2 subplots) that includes: \n",
    "# - Sales over time, Category comparison, Price vs Rating scatter\n",
    "# - Quantity distribution, Top 5 products bar chart, Monthly growth line \n",
    "# Customize each subplot with titles, labels, and legends \n",
    "\n",
    "# Q26: Create a second DataFrame with customer information: \n",
    "# Columns: CustomerID, CustomerName, City, SignupDate \n",
    "# Merge this with the sales DataFrame using CustomerID (inner, left, right, outer joins) \n",
    "# Demonstrate the difference between merge and join operations \n",
    "# Q27: Create three separate DataFrames for three different months of sales data \n",
    "# Concatenate them vertically (along rows) and horizontally (along columns)\n",
    "# Remove duplicate records if any and reset the index \n",
    "\n",
    "# Q28: Convert OrderDate column to datetime format \n",
    "# Extract: Year, Month, Day, DayOfWeek, Quarter from OrderDate \n",
    "# Create a time series analysis showing sales trends by month and quarter \n",
    "# Calculate rolling 7-day average of sales \n",
    "\n",
    "# Q29: Using the Review column, perform comprehensive text analysis: \n",
    "# - Tokenize all reviews into words \n",
    "# - Remove stopwords from reviews \n",
    "# - Apply stemming and lemmatization \n",
    "# - Perform POS tagging on sample reviews \n",
    "# - Create frequency distribution of top 20 most common words \n",
    "# - Visualize word frequency using a bar chart \n",
    "\n",
    "# Q30: Convert Quantity, Price, and Rating columns to TensorFlow tensors \n",
    "# Create TensorFlow variables for Price and update them with 15% price increase \n",
    "# Perform tensor operations: \n",
    "# - Calculate predicted revenue using matrix multiplication \n",
    "# - Apply mathematical functions (square, sqrt, exponential) on tensors \n",
    "# - Demonstrate in-place operations and variable updates \n",
    "# Display tensor properties: shape, dtype, rank \n",
    "\n",
    "# After completing all analysis, export the final cleaned and processed DataFrame to: \n",
    "# - CSV file: 'final_sales_analysis.csv' \n",
    "# Include only relevant columns and exclude any temporary columns created during analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f33195-395c-470b-8f16-efaf6c12d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c87c96a5-50c6-4cc0-ab28-40747eb63898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ten records: \n",
      "  OrderID CustomerID              Product Category  Quantity  Price  \\\n",
      "0   D-001   CUST-001  Bhajake Pohe Chiwda   Chiwda    1000.0  600.0   \n",
      "1   D-002   CUST-002     Chakali(Bhajani)  Chakali    1500.0  600.0   \n",
      "2   D-003   CUST-003     Chakali(Bhajani)  Chakali    1000.0  600.0   \n",
      "3   D-004   CUST-004           Rava Ladoo    Ladoo     500.0  650.0   \n",
      "4   D-005   CUST-005    Patal Pohe Chiwda   Chiwda     125.0  600.0   \n",
      "5   D-006   CUST-006     Chakali(Bhajani)  Chakali     500.0  600.0   \n",
      "6   D-007   CUST-007  Bhajake Pohe Chiwda   Chiwda    1000.0  600.0   \n",
      "7   D-008   CUST-008     Chakali(Bhajani)  Chakali     500.0  600.0   \n",
      "8   D-009   CUST-009     Chakali(Bhajani)  Chakali    1000.0  600.0   \n",
      "9   D-010   CUST-010     Chakali(Bhajani)  Chakali     500.0  600.0   \n",
      "\n",
      "    OrderDate  Rating              Review  \n",
      "0  2025-10-14     3.0   Loved the texture  \n",
      "1  2025-10-19     5.0                 NaN  \n",
      "2  2025-10-19     4.0  Packaging was good  \n",
      "3  2025-10-17     3.0                 NaN  \n",
      "4  2025-10-21     4.0                 NaN  \n",
      "5  2025-10-16     NaN                 NaN  \n",
      "6  2025-10-09     4.0  Perfect for Diwali  \n",
      "7  2025-10-20     3.0                 NaN  \n",
      "8  2025-10-18     4.0                 NaN  \n",
      "9  2025-10-19     3.0     Value for money  \n",
      "last five records: \n",
      "    OrderID CustomerID             Product     Category  Quantity  Price  \\\n",
      "145   D-080   CUST-025    Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "146   D-080   CUST-025  Shankarpali(Sweet)  Shankarpali     500.0  600.0   \n",
      "147   D-081   CUST-073    Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "148   D-081   CUST-073         Besan Ladoo        Ladoo     500.0  750.0   \n",
      "149   D-082   CUST-074    Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "\n",
      "      OrderDate  Rating             Review  \n",
      "145  2025-10-18     NaN                NaN  \n",
      "146  2025-10-18     3.0  Loved the texture  \n",
      "147  2025-10-18     NaN                NaN  \n",
      "148  2025-10-18     5.0  Everyone loved it  \n",
      "149  2025-10-18     4.0                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Q1: Create a DataFrame with the following e-commerce sales data: \n",
    "# Columns: OrderID, CustomerID, Product, Category, Quantity, Price, OrderDate, Rating, Review \n",
    "# Create at least 50 sample records with realistic data including dates from 2023-2024 \n",
    "# Display the first 10 and last 5 records using head() and tail() \n",
    "df = pd.read_csv('mahalaxmi_foods.csv')\n",
    "print(f\"first ten records: \\n{df.head(10)}\")\n",
    "print(f\"last five records: \\n{df.tail(5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "029e33b3-b2f0-4fb8-b7aa-7d5586a3c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   OrderID     150 non-null    object \n",
      " 1   CustomerID  150 non-null    object \n",
      " 2   Product     150 non-null    object \n",
      " 3   Category    150 non-null    object \n",
      " 4   Quantity    150 non-null    float64\n",
      " 5   Price       150 non-null    float64\n",
      " 6   OrderDate   150 non-null    object \n",
      " 7   Rating      122 non-null    float64\n",
      " 8   Review      63 non-null     object \n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 10.7+ KB\n",
      "None\n",
      "           Quantity       Price      Rating\n",
      "count    150.000000  150.000000  122.000000\n",
      "mean    1119.500000  611.333333    3.975410\n",
      "std     2578.451733   74.892914    0.827853\n",
      "min      125.000000  300.000000    3.000000\n",
      "25%      500.000000  600.000000    3.000000\n",
      "50%      500.000000  600.000000    4.000000\n",
      "75%     1000.000000  650.000000    5.000000\n",
      "max    30000.000000  800.000000    5.000000\n",
      "Index(['OrderID', 'CustomerID', 'Product', 'Category', 'Quantity', 'Price',\n",
      "       'OrderDate', 'Rating', 'Review'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Q2: Use info() and describe() to get a comprehensive overview of the dataset \n",
    "# Identify data types, missing values, and statistical summary \n",
    "# Print the column names using columns attribute and shape of the dataset \n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ca3829-56bb-405e-b718-d6c00976dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   OrderID          150 non-null    object \n",
      " 1   CustomerID       150 non-null    object \n",
      " 2   Product          150 non-null    object \n",
      " 3   Category         150 non-null    object \n",
      " 4   Quantity         150 non-null    float64\n",
      " 5   Price            150 non-null    float64\n",
      " 6   OrderDate        150 non-null    object \n",
      " 7   Rating           150 non-null    float64\n",
      " 8   Review           150 non-null    object \n",
      " 9   TotalAmount      150 non-null    float64\n",
      " 10  DiscountedPrice  150 non-null    float64\n",
      "dtypes: float64(5), object(6)\n",
      "memory usage: 13.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Q3: Introduce 10% missing values randomly in Rating and Review columns \n",
    "# Detect missing values and display the count of missing values per column \n",
    "# Fill missing ratings with the median rating and missing reviews with \"No review provided\" \n",
    "\n",
    "df['Rating'] = df['Rating'].fillna(df['Rating'].median())\n",
    "df['Review'] = df['Review'].fillna(\"No review provided\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea7cd4d7-734a-4fc8-9662-f39378457b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    OrderID CustomerID              Product     Category  Quantity  Price  \\\n",
      "0     D-001   CUST-001  Bhajake Pohe Chiwda       Chiwda    1000.0  600.0   \n",
      "1     D-002   CUST-002     Chakali(Bhajani)      Chakali    1500.0  600.0   \n",
      "2     D-003   CUST-003     Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "3     D-004   CUST-004           Rava Ladoo        Ladoo     500.0  650.0   \n",
      "4     D-005   CUST-005    Patal Pohe Chiwda       Chiwda     125.0  600.0   \n",
      "..      ...        ...                  ...          ...       ...    ...   \n",
      "145   D-080   CUST-025     Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "146   D-080   CUST-025   Shankarpali(Sweet)  Shankarpali     500.0  600.0   \n",
      "147   D-081   CUST-073     Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "148   D-081   CUST-073          Besan Ladoo        Ladoo     500.0  750.0   \n",
      "149   D-082   CUST-074     Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "\n",
      "      OrderDate  Rating              Review  TotalAmount  DiscountedPrice  \n",
      "0    2025-10-14     3.0   Loved the texture        600.0            600.0  \n",
      "1    2025-10-19     5.0  No review provided        900.0            900.0  \n",
      "2    2025-10-19     4.0  Packaging was good        600.0            600.0  \n",
      "3    2025-10-17     3.0  No review provided        325.0            325.0  \n",
      "4    2025-10-21     4.0  No review provided         75.0             75.0  \n",
      "..          ...     ...                 ...          ...              ...  \n",
      "145  2025-10-18     4.0  No review provided        300.0            300.0  \n",
      "146  2025-10-18     3.0   Loved the texture        300.0            300.0  \n",
      "147  2025-10-18     4.0  No review provided        300.0            300.0  \n",
      "148  2025-10-18     5.0   Everyone loved it        375.0            375.0  \n",
      "149  2025-10-18     4.0  No review provided        300.0            300.0  \n",
      "\n",
      "[150 rows x 11 columns]\n",
      "Orders Above 1500rs\n",
      "    OrderID CustomerID           Product Category  Quantity  Price  \\\n",
      "11    D-012   CUST-012  Chakali(Bhajani)  Chakali   30000.0  600.0   \n",
      "12    D-013   CUST-013  Chakali(Bhajani)  Chakali    4000.0  600.0   \n",
      "14    D-015   CUST-015  Chakali(Bhajani)  Chakali   10000.0  600.0   \n",
      "20    D-021   CUST-021           Karanji  Karanji    3000.0  700.0   \n",
      "38    D-042   CUST-039  Chakali(Bhajani)  Chakali    3000.0  600.0   \n",
      "40    D-044   CUST-041           Karanji  Karanji    2500.0  700.0   \n",
      "142   D-079   CUST-072      Boondi Ladoo    Ladoo    3000.0  550.0   \n",
      "\n",
      "      OrderDate  Rating              Review  TotalAmount  DiscountedPrice  \n",
      "11   2025-10-10     3.0   Loved the texture      18000.0          16200.0  \n",
      "12   2025-10-15     5.0  Packaging was good       2400.0           2160.0  \n",
      "14   2025-10-15     5.0  No review provided       6000.0           5400.0  \n",
      "20   2025-10-18     4.0  No review provided       2100.0           1890.0  \n",
      "38   2025-10-16     4.0          Delicious!       1800.0           1620.0  \n",
      "40   2025-10-16     5.0  Packaging was good       1750.0           1575.0  \n",
      "142  2025-10-18     4.0  No review provided       1650.0           1485.0  \n"
     ]
    }
   ],
   "source": [
    "# Q4: Create a new column 'TotalAmount' by multiplying Quantity and Price \n",
    "# Add another column 'DiscountedPrice' that applies 10% discount on orders above $100 \n",
    "# Use conditional selection to filter orders where TotalAmount > $150 \n",
    "df['TotalAmount'] = (df['Quantity'] * df['Price']) / 1000\n",
    "df['DiscountedPrice'] = df['TotalAmount'].apply(lambda x: x * 0.9 if x > 1000 else x)\n",
    "print(df)\n",
    "filtered_orders = df[df['TotalAmount'] > 1500]\n",
    "print(\"Orders Above 1500rs\")\n",
    "print(filtered_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e86ddd-1d1c-40c9-9081-f1b31b5cd4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Product     Category  TotalAmount  Rating\n",
      "0    Bhajake Pohe Chiwda       Chiwda        600.0     3.0\n",
      "1       Chakali(Bhajani)      Chakali        900.0     5.0\n",
      "2       Chakali(Bhajani)      Chakali        600.0     4.0\n",
      "3             Rava Ladoo        Ladoo        325.0     3.0\n",
      "4      Patal Pohe Chiwda       Chiwda         75.0     4.0\n",
      "..                   ...          ...          ...     ...\n",
      "145     Chakali(Bhajani)      Chakali        300.0     4.0\n",
      "146   Shankarpali(Sweet)  Shankarpali        300.0     3.0\n",
      "147     Chakali(Bhajani)      Chakali        300.0     4.0\n",
      "148          Besan Ladoo        Ladoo        375.0     5.0\n",
      "149     Chakali(Bhajani)      Chakali        300.0     4.0\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "          Product Category  TotalAmount  Rating\n",
      "41    Besan Ladoo    Ladoo        750.0     5.0\n",
      "53     Oats Ladoo    Ladoo        400.0     5.0\n",
      "73     Rava Ladoo    Ladoo        650.0     5.0\n",
      "74    Besan Ladoo    Ladoo        750.0     4.0\n",
      "80     Rava Ladoo    Ladoo        650.0     4.0\n",
      "86     Rava Ladoo    Ladoo        325.0     5.0\n",
      "100  Boondi Ladoo    Ladoo        550.0     5.0\n",
      "102   Besan Ladoo    Ladoo        375.0     5.0\n",
      "112   Besan Ladoo    Ladoo        375.0     4.0\n",
      "118  Boondi Ladoo    Ladoo        825.0     4.0\n",
      "126    Rava Ladoo    Ladoo        325.0     4.0\n",
      "133  Boondi Ladoo    Ladoo        550.0     4.0\n",
      "136   Besan Ladoo    Ladoo        375.0     5.0\n",
      "141    Rava Ladoo    Ladoo        162.5     4.0\n",
      "142  Boondi Ladoo    Ladoo       1650.0     4.0\n",
      "144    Rava Ladoo    Ladoo        650.0     5.0\n",
      "148   Besan Ladoo    Ladoo        375.0     5.0\n"
     ]
    }
   ],
   "source": [
    "# Q5: Select only the columns: Product, Category, TotalAmount, and Rating \n",
    "# Filter and display all orders from the 'Electronics' category with Rating >= 4 \n",
    "selected_df = df[['Product', 'Category', 'TotalAmount','Rating' ]]\n",
    "print(selected_df)\n",
    "filtered_ladoo = selected_df[(selected_df['Category'] == 'Ladoo') & (selected_df['Rating'] >=4.0)]\n",
    "print(filtered_ladoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b5ff137-374c-4987-bec8-fe1aa103bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of orders according to filter: 44\n",
      "    OrderID CustomerID               Product     Category  Quantity  Price  \\\n",
      "1     D-002   CUST-002      Chakali(Bhajani)      Chakali    1500.0  600.0   \n",
      "11    D-012   CUST-012      Chakali(Bhajani)      Chakali   30000.0  600.0   \n",
      "12    D-013   CUST-013      Chakali(Bhajani)      Chakali    4000.0  600.0   \n",
      "14    D-015   CUST-015      Chakali(Bhajani)      Chakali   10000.0  600.0   \n",
      "15    D-016   CUST-016      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "16    D-017   CUST-017      Chakali(Bhajani)      Chakali     750.0  600.0   \n",
      "17    D-018   CUST-018    Shankarpali(Sweet)  Shankarpali    1500.0  600.0   \n",
      "20    D-021   CUST-021               Karanji      Karanji    3000.0  700.0   \n",
      "23    D-024   CUST-030   Bhajake Pohe Chiwda       Chiwda     500.0  600.0   \n",
      "24    D-025   CUST-024      Chakali(Bhajani)      Chakali    2000.0  600.0   \n",
      "26    D-027   CUST-026               Karanji      Karanji    1000.0  700.0   \n",
      "27    D-028   CUST-027      Chakali(Bhajani)      Chakali     500.0  600.0   \n",
      "30    D-034   CUST-031     Patal Pohe Chiwda       Chiwda     500.0  600.0   \n",
      "38    D-042   CUST-039      Chakali(Bhajani)      Chakali    3000.0  600.0   \n",
      "40    D-044   CUST-041               Karanji      Karanji    2500.0  700.0   \n",
      "41    D-045   CUST-042           Besan Ladoo        Ladoo    1000.0  750.0   \n",
      "46    D-050   CUST-047      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "53    D-054   CUST-050            Oats Ladoo        Ladoo     500.0  800.0   \n",
      "56    D-056   CUST-051     Patal Pohe Chiwda       Chiwda    1000.0  600.0   \n",
      "58    D-056   CUST-051      Chakali(Bhajani)      Chakali     750.0  600.0   \n",
      "60    D-056   CUST-051     Kolhapuri Bhadang       Chiwda     750.0  500.0   \n",
      "72    D-060   CUST-055    Shankarpali(Sweet)  Shankarpali    1500.0  600.0   \n",
      "73    D-060   CUST-055            Rava Ladoo        Ladoo    1000.0  650.0   \n",
      "76    D-060   CUST-055               Anarase      Anarase     500.0  700.0   \n",
      "78    D-061   CUST-056      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "82    D-062   CUST-057    Shankarpali(Sweet)  Shankarpali    1000.0  600.0   \n",
      "83    D-063   CUST-058     Patal Pohe Chiwda       Chiwda     500.0  600.0   \n",
      "85    D-063   CUST-058            Sadhi Shev         Shev     500.0  500.0   \n",
      "86    D-063   CUST-058            Rava Ladoo        Ladoo     500.0  650.0   \n",
      "89    D-063   CUST-058    Shankarpali(Sweet)  Shankarpali     500.0  600.0   \n",
      "93    D-064   CUST-059  Shankarpali(Namkeen)  Shankarpali     500.0  500.0   \n",
      "94    D-065   CUST-060      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "95    D-065   CUST-060     Patal Pohe Chiwda       Chiwda     250.0  600.0   \n",
      "100   D-066   CUST-061          Boondi Ladoo        Ladoo    1000.0  550.0   \n",
      "102   D-067   CUST-062           Besan Ladoo        Ladoo     500.0  750.0   \n",
      "119   D-073   CUST-027      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "122   D-073   CUST-027    Shankarpali(Sweet)  Shankarpali     250.0  600.0   \n",
      "123   D-073   CUST-027  Shankarpali(Namkeen)  Shankarpali     250.0  500.0   \n",
      "134   D-076   CUST-069      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "136   D-076   CUST-069           Besan Ladoo        Ladoo     500.0  750.0   \n",
      "138   D-078   CUST-071      Chakali(Bhajani)      Chakali    1000.0  600.0   \n",
      "142   D-079   CUST-072          Boondi Ladoo        Ladoo    3000.0  550.0   \n",
      "144   D-079   CUST-072            Rava Ladoo        Ladoo    1000.0  650.0   \n",
      "148   D-081   CUST-073           Besan Ladoo        Ladoo     500.0  750.0   \n",
      "\n",
      "      OrderDate  Rating                Review  TotalAmount  DiscountedPrice  \n",
      "1    2025-10-19     5.0    No review provided        900.0            900.0  \n",
      "11   2025-10-10     3.0     Loved the texture      18000.0          16200.0  \n",
      "12   2025-10-15     5.0    Packaging was good       2400.0           2160.0  \n",
      "14   2025-10-15     5.0    No review provided       6000.0           5400.0  \n",
      "15   2025-10-19     5.0       Value for money        600.0            600.0  \n",
      "16   2025-10-17     5.0          Good quality        450.0            450.0  \n",
      "17   2025-10-18     5.0    No review provided        900.0            900.0  \n",
      "20   2025-10-18     4.0    No review provided       2100.0           1890.0  \n",
      "23   2025-10-18     5.0    Perfect for Diwali        300.0            300.0  \n",
      "24   2025-10-16     5.0  Very authentic taste       1200.0           1080.0  \n",
      "26   2025-10-18     5.0  Very authentic taste        700.0            700.0  \n",
      "27   2025-10-13     5.0    No review provided        300.0            300.0  \n",
      "30   2025-10-18     5.0    No review provided        300.0            300.0  \n",
      "38   2025-10-16     4.0            Delicious!       1800.0           1620.0  \n",
      "40   2025-10-16     5.0    Packaging was good       1750.0           1575.0  \n",
      "41   2025-10-18     5.0    No review provided        750.0            750.0  \n",
      "46   2025-10-15     5.0  A bit spicy but good        600.0            600.0  \n",
      "53   2025-10-19     5.0       Fresh and tasty        400.0            400.0  \n",
      "56   2025-10-15     5.0       Value for money        600.0            600.0  \n",
      "58   2025-10-15     5.0     Everyone loved it        450.0            450.0  \n",
      "60   2025-10-15     5.0  A bit spicy but good        375.0            375.0  \n",
      "72   2025-10-19     5.0     Loved the texture        900.0            900.0  \n",
      "73   2025-10-19     5.0  Very authentic taste        650.0            650.0  \n",
      "76   2025-10-19     5.0    No review provided        350.0            350.0  \n",
      "78   2025-10-18     5.0  A bit spicy but good        600.0            600.0  \n",
      "82   2025-10-17     5.0      Best snacks ever        600.0            600.0  \n",
      "83   2025-10-19     5.0    No review provided        300.0            300.0  \n",
      "85   2025-10-19     5.0    No review provided        250.0            250.0  \n",
      "86   2025-10-19     5.0    No review provided        325.0            325.0  \n",
      "89   2025-10-19     5.0    No review provided        300.0            300.0  \n",
      "93   2025-10-19     5.0       Fresh and tasty        250.0            250.0  \n",
      "94   2025-10-17     5.0    Highly recommended        600.0            600.0  \n",
      "95   2025-10-17     5.0          Good quality        150.0            150.0  \n",
      "100  2025-10-19     5.0    No review provided        550.0            550.0  \n",
      "102  2025-10-18     5.0      Best snacks ever        375.0            375.0  \n",
      "119  2025-10-17     5.0    No review provided        600.0            600.0  \n",
      "122  2025-10-17     5.0    No review provided        150.0            150.0  \n",
      "123  2025-10-17     5.0    No review provided        125.0            125.0  \n",
      "134  2025-10-19     5.0    No review provided        600.0            600.0  \n",
      "136  2025-10-19     5.0         Simply superb        375.0            375.0  \n",
      "138  2025-10-18     5.0    No review provided        600.0            600.0  \n",
      "142  2025-10-18     4.0    No review provided       1650.0           1485.0  \n",
      "144  2025-10-18     5.0  A bit spicy but good        650.0            650.0  \n",
      "148  2025-10-18     5.0     Everyone loved it        375.0            375.0  \n"
     ]
    }
   ],
   "source": [
    "# Q6: Use boolean indexing to find all orders where: \n",
    "# - Quantity > 2 AND Price < 50 OR Rating == 5 \n",
    "# Display the count of such orders \n",
    "filtered_1 = df[(df['Quantity'] > 2000) & (df['Price'] > 500) | (df['Rating'] == 5.0)]\n",
    "print(f\"No of orders according to filter: {len(filtered_1)}\")\n",
    "print(filtered_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e485583b-a23b-415e-bb34-fe12d51086d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderID CustomerID              Product Category  Quantity  Price  \\\n",
      "54   D-055   CUST-050  Bhajake Pohe Chiwda   Chiwda    1250.0  600.0   \n",
      "55   D-055   CUST-050         Boondi Ladoo    Ladoo    1250.0  550.0   \n",
      "4    D-005   CUST-005    Patal Pohe Chiwda   Chiwda     125.0  600.0   \n",
      "7    D-008   CUST-008     Chakali(Bhajani)  Chakali     500.0  600.0   \n",
      "36   D-040   CUST-037     Chakali(Bhajani)  Chakali    2000.0  600.0   \n",
      "..     ...        ...                  ...      ...       ...    ...   \n",
      "18   D-019   CUST-019     Chakali(Bhajani)  Chakali    1000.0  600.0   \n",
      "19   D-020   CUST-020             A1 ladoo    Ladoo     300.0  800.0   \n",
      "11   D-012   CUST-012     Chakali(Bhajani)  Chakali   30000.0  600.0   \n",
      "10   D-011   CUST-011     Chakali(Bhajani)  Chakali    1000.0  600.0   \n",
      "6    D-007   CUST-007  Bhajake Pohe Chiwda   Chiwda    1000.0  600.0   \n",
      "\n",
      "     OrderDate  Rating              Review  TotalAmount  DiscountedPrice  \\\n",
      "54  2025-10-23     4.0  No review provided        750.0            750.0   \n",
      "55  2025-10-23     3.0  No review provided        687.5            687.5   \n",
      "4   2025-10-21     4.0  No review provided         75.0             75.0   \n",
      "7   2025-10-20     3.0  No review provided        300.0            300.0   \n",
      "36  2025-10-19     4.0  No review provided       1200.0           1080.0   \n",
      "..         ...     ...                 ...          ...              ...   \n",
      "18  2025-10-11     3.0  Packaging was good        600.0            600.0   \n",
      "19  2025-10-11     3.0        Good quality        240.0            240.0   \n",
      "11  2025-10-10     3.0   Loved the texture      18000.0          16200.0   \n",
      "10  2025-10-10     4.0  No review provided        600.0            600.0   \n",
      "6   2025-10-09     4.0  Perfect for Diwali        600.0            600.0   \n",
      "\n",
      "    SalesRank  \n",
      "54       21.0  \n",
      "55       27.0  \n",
      "4       150.0  \n",
      "7        97.0  \n",
      "36       10.0  \n",
      "..        ...  \n",
      "18       31.0  \n",
      "19      138.0  \n",
      "11        1.0  \n",
      "10       31.0  \n",
      "6        31.0  \n",
      "\n",
      "[150 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Q7: Sort the entire DataFrame by OrderDate (descending) and then by TotalAmount (descending) \n",
    "# Create a new column 'SalesRank' that ranks products by TotalAmount in descending order \n",
    "df_sorted = df.sort_values(by=['OrderDate', 'TotalAmount'], ascending=False)\n",
    "df_sorted['SalesRank'] = df_sorted['TotalAmount'].rank(ascending=False, method='min')\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2ac5732-e61a-478c-b2f6-9b8921f57194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Product  Quantity\n",
      "5      Chakali(Bhajani)   90750.0\n",
      "7               Karanji   14500.0\n",
      "4          Boondi Ladoo    9250.0\n",
      "3   Bhajake Pohe Chiwda    7250.0\n",
      "14   Shankarpali(Sweet)    7250.0\n"
     ]
    }
   ],
   "source": [
    "# Q8: Find the top 5 best-selling products based on total quantity sold \n",
    "# Display the product name and total quantity in descending order \n",
    "\n",
    "product_sales = df.groupby('Product')['Quantity'].sum().reset_index()\n",
    "\n",
    "top_5_products = product_sales.sort_values(by='Quantity', ascending=False).head(5)\n",
    "\n",
    "print(top_5_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07f6686c-f6fd-4500-970e-845313f78be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Total_Sales  Average_Rating  Order_Count\n",
      "Category                                             \n",
      "Chakali          54450.0        3.923077           52\n",
      "Ladoo            13665.0        4.083333           24\n",
      "Karanji          10150.0        3.875000           16\n",
      "Chiwda            7975.0        4.200000           20\n",
      "Shankarpali       6225.0        4.176471           17\n",
      "Shev              3875.0        3.727273           11\n",
      "Anarase           2800.0        3.777778            9\n",
      "Other             1500.0        3.000000            1\n"
     ]
    }
   ],
   "source": [
    "# Q9: Group the data by 'Category' and calculate: \n",
    "# - Total sales (sum of TotalAmount) \n",
    "# - Average rating \n",
    "# - Number of orders \n",
    "# Display the results sorted by total sales \n",
    "\n",
    "category_summary = df.groupby('Category').agg(\n",
    "    Total_Sales=('TotalAmount', 'sum'),\n",
    "    Average_Rating=('Rating', 'mean'),\n",
    "    Order_Count=('OrderID', 'count')\n",
    ")\n",
    "category_summary = category_summary.sort_index().sort_values(by='Total_Sales', ascending=False)\n",
    "\n",
    "print(category_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e986b9a1-0163-4161-8135-9d5aa21c1004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table: Avg Price by Category & Rating\n",
      "Rating              3.0         4.0         5.0\n",
      "Category                                       \n",
      "Anarase      700.000000  700.000000  700.000000\n",
      "Chakali      600.000000  600.000000  600.000000\n",
      "Chiwda       550.000000  583.333333  583.333333\n",
      "Karanji      700.000000  700.000000  700.000000\n",
      "Ladoo        671.428571  637.500000  700.000000\n",
      "Other        300.000000         NaN         NaN\n",
      "Shankarpali  550.000000  550.000000  571.428571\n",
      "Shev         500.000000  500.000000  500.000000\n",
      "Multi-Column Groupby Aggregation\n",
      "                                 TotalAmount              Quantity    Rating\n",
      "                                         sum         mean      sum      mean\n",
      "Category    Product                                                         \n",
      "Anarase     Anarase                   2800.0   311.111111   4000.0  3.777778\n",
      "Chakali     Chakali(Bhajani)         54450.0  1047.115385  90750.0  3.923077\n",
      "Chiwda      Bhajake Pohe Chiwda       4350.0   483.333333   7250.0  4.000000\n",
      "            Kolhapuri Bhadang         1000.0   250.000000   2000.0  4.000000\n",
      "            Patal Pohe Chiwda         2625.0   375.000000   4375.0  4.571429\n",
      "Karanji     Karanji                  10150.0   634.375000  14500.0  3.875000\n",
      "Ladoo       A1 ladoo                   240.0   240.000000    300.0  3.000000\n",
      "            Besan Ladoo               4687.5   585.937500   6250.0  4.250000\n",
      "            Boondi Ladoo              5087.5   847.916667   9250.0  3.833333\n",
      "            Oats Ladoo                 400.0   400.000000    500.0  5.000000\n",
      "            Rava Ladoo                3250.0   406.250000   5000.0  4.125000\n",
      "Other       Gift Box                  1500.0  1500.000000   5000.0  3.000000\n",
      "Shankarpali Shankarpali(Namkeen)      1875.0   267.857143   3750.0  4.000000\n",
      "            Shankarpali(Sweet)        4350.0   435.000000   7250.0  4.300000\n",
      "Shev        Sadhi Shev                1500.0   300.000000   3000.0  4.200000\n",
      "            Tikhat Shev               2375.0   395.833333   4750.0  3.333333\n"
     ]
    }
   ],
   "source": [
    "# Q10: Create a pivot table showing average Price for each Category and Rating combination \n",
    "# Use groupby with multiple columns (Category, Product) and aggregate multiple functions \n",
    "\n",
    "pivot_price = df.pivot_table(\n",
    "    values='Price', \n",
    "    index='Category', \n",
    "    columns='Rating', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "multi_group = df.groupby(['Category', 'Product']).agg({\n",
    "    'TotalAmount': ['sum', 'mean'],\n",
    "    'Quantity': 'sum',\n",
    "    'Rating': 'mean'\n",
    "})\n",
    "\n",
    "print(\"Pivot Table: Avg Price by Category & Rating\")\n",
    "print(pivot_price)\n",
    "print(\"Multi-Column Groupby Aggregation\")\n",
    "print(multi_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84e208b7-1dcf-4b39-bf7f-26180db93009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: \n",
      " [[ 1000.   600.]\n",
      " [ 1500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   650.]\n",
      " [  125.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [30000.   600.]\n",
      " [ 4000.   600.]\n",
      " [ 1000.   600.]\n",
      " [10000.   600.]\n",
      " [ 1000.   600.]\n",
      " [  750.   600.]\n",
      " [ 1500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  300.   800.]\n",
      " [ 3000.   700.]\n",
      " [ 1000.   600.]\n",
      " [ 2000.   600.]\n",
      " [  500.   600.]\n",
      " [ 2000.   600.]\n",
      " [ 2000.   600.]\n",
      " [ 1000.   700.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   600.]\n",
      " [ 1500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   500.]\n",
      " [ 1000.   600.]\n",
      " [ 1500.   550.]\n",
      " [ 2000.   600.]\n",
      " [  250.   700.]\n",
      " [ 3000.   600.]\n",
      " [  500.   600.]\n",
      " [ 2500.   700.]\n",
      " [ 1000.   750.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [  500.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  250.   500.]\n",
      " [  500.   600.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [  500.   800.]\n",
      " [ 1250.   600.]\n",
      " [ 1250.   550.]\n",
      " [ 1000.   600.]\n",
      " [  500.   700.]\n",
      " [  750.   600.]\n",
      " [ 1500.   500.]\n",
      " [  750.   500.]\n",
      " [  250.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   500.]\n",
      " [  500.   500.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [ 1000.   600.]\n",
      " [ 1500.   600.]\n",
      " [ 1000.   650.]\n",
      " [ 1000.   750.]\n",
      " [  500.   500.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   500.]\n",
      " [ 1000.   650.]\n",
      " [ 1500.   700.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   500.]\n",
      " [  500.   500.]\n",
      " [  500.   650.]\n",
      " [  500.   700.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   500.]\n",
      " [  500.   600.]\n",
      " [  250.   500.]\n",
      " [  500.   500.]\n",
      " [ 1000.   600.]\n",
      " [  250.   600.]\n",
      " [  500.   500.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [ 1000.   550.]\n",
      " [ 1000.   500.]\n",
      " [  500.   750.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   700.]\n",
      " [  500.   500.]\n",
      " [  500.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   500.]\n",
      " [  500.   500.]\n",
      " [  500.   750.]\n",
      " [  250.   650.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [ 5000.   300.]\n",
      " [ 1000.   700.]\n",
      " [ 1500.   550.]\n",
      " [ 1000.   600.]\n",
      " [  500.   700.]\n",
      " [  250.   700.]\n",
      " [  250.   600.]\n",
      " [  250.   500.]\n",
      " [  500.   600.]\n",
      " [  500.   500.]\n",
      " [  500.   650.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [  500.   600.]\n",
      " [  500.   700.]\n",
      " [  500.   700.]\n",
      " [ 1000.   500.]\n",
      " [ 1000.   550.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   500.]\n",
      " [  500.   750.]\n",
      " [ 1000.   600.]\n",
      " [ 1000.   600.]\n",
      " [  500.   600.]\n",
      " [  250.   750.]\n",
      " [  250.   650.]\n",
      " [ 3000.   550.]\n",
      " [ 2000.   750.]\n",
      " [ 1000.   650.]\n",
      " [  500.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   600.]\n",
      " [  500.   750.]\n",
      " [  500.   600.]]\n",
      "Shape: (150, 2)\n",
      "dtype: float64\n",
      "ndim: 2\n",
      "size: 300\n"
     ]
    }
   ],
   "source": [
    "# Q11: Convert the Quantity and Price columns to NumPy arrays \n",
    "# Create a 2D array combining these two columns \n",
    "# Display array properties: shape, dtype, ndim, size\n",
    "import numpy as np\n",
    "quantity_arr = np.array(df['Quantity'])\n",
    "price_arr = np.array(df['Price'])\n",
    "combined_arr = np.column_stack((quantity_arr, price_arr))\n",
    "print(\"Array: \\n\", combined_arr)\n",
    "print(f\"Shape: {combined_arr.shape}\")\n",
    "print(f\"dtype: {combined_arr.dtype}\")\n",
    "print(f\"ndim: {combined_arr.ndim}\")\n",
    "print(f\"size: {combined_arr.size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0857f355-285e-4b9c-9ad5-22be0ca72b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 272.6746543704302\n",
      "median: 280.32244184797605\n",
      "standard deviation: 147.45075326974782\n",
      "min: 16.329729011603813\n",
      "max: 498.38795269476293\n",
      "[[251.40537334 451.18908968 213.36058748 433.59831378 331.64193207\n",
      "  252.09137162  42.11386719 344.88738271 438.93267964 283.39296612]\n",
      " [315.83510989  46.98084091 256.66800057 334.9945355  271.57959724\n",
      "  154.65705301  82.20068219  17.41929718  64.57832537 115.57691841]\n",
      " [417.57148758 254.52291505 298.37196476 204.32798821 220.25201869\n",
      "  219.77898794 430.25610736 357.13589756 180.28317983 216.41777195]\n",
      " [ 61.23412498 221.60101784  52.36584411  89.53845882 312.39329685\n",
      "  436.4783298  425.29578223 103.85771159 461.23396296 102.82266694]\n",
      " [457.25585169 279.14374054 181.83879396 427.06281774  89.19544423\n",
      "  361.75485531 378.58787065 498.20244723  93.4516195  498.38795269]\n",
      " [468.83384389  16.32972901 458.44247294 241.78129889 347.31965862\n",
      "  401.87454388 251.57995675 491.25393165 281.50114316 490.35896114]\n",
      " [ 92.30507543 197.59691711 305.74579855 395.51857177 135.0268345\n",
      "  480.98701104 153.05148306 115.01930481 397.87299096 273.08336159]\n",
      " [475.62007634  22.21296941  45.10020675 246.55607388  17.79221062\n",
      "  336.10636739  81.97331276 217.03674796  66.66552649 152.36680769]\n",
      " [121.38365475 390.12506494 388.71152424 176.3384975  319.68642515\n",
      "  465.91300735 288.5478754  406.29581683 492.90316131 491.28374831]\n",
      " [291.06034423 103.211028   488.67488499 313.8047287  350.37038126\n",
      "  406.61039538 162.76622842  52.3438114  407.2775908  459.51924755]]\n"
     ]
    }
   ],
   "source": [
    "# Q12: Create a 1D NumPy array of 100 random prices between 10 and 500 \n",
    "# Calculate mean, median, standard deviation, min, and max using NumPy functions \n",
    "# Reshape this array into a 10x10 matrix \n",
    "rand_prices = np.random.uniform(10,500,100)\n",
    "print(f\"Mean: {np.mean(rand_prices)}\")\n",
    "print(f\"median: {np.median(rand_prices)}\")\n",
    "print(f\"standard deviation: {np.std(rand_prices)}\")\n",
    "print(f\"min: {np.min(rand_prices)}\")\n",
    "print(f\"max: {np.max(rand_prices)}\")\n",
    "rand_prices_matrix = rand_prices.reshape(10,10)\n",
    "print(rand_prices_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a413cce-3bf8-42bb-ac87-2b748b4430dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Array 1 ---\n",
      "[[[82 55 99]\n",
      "  [20 97 42]\n",
      "  [73 54 14]]\n",
      "\n",
      " [[60 47 18]\n",
      "  [95 22 48]\n",
      "  [55 46 83]]\n",
      "\n",
      " [[52 21 99]\n",
      "  [23 66 67]\n",
      "  [20 27 61]]]\n",
      "\n",
      "--- Matrix Multiplication Result ---\n",
      "[[[16401  7688 13973]\n",
      "  [ 8677  4248 13147]\n",
      "  [ 9618  2625  6859]]\n",
      "\n",
      " [[ 8551  4127  9321]\n",
      "  [12031  7057 12236]\n",
      "  [11234 10107 11388]]\n",
      "\n",
      " [[ 8032  5181  7100]\n",
      "  [ 8415  7628  5149]\n",
      "  [ 5592  4259  4084]]]\n",
      "\n",
      "--- Values > 50 in Array 1 ---\n",
      "[82 55 99 97 73 54 60 95 55 83 52 99 66 67 61]\n"
     ]
    }
   ],
   "source": [
    "# Q13: Create two 3D NumPy arrays (3x3x3) with random integers \n",
    "# Perform element-wise addition, multiplication, and matrix multiplication \n",
    "# Use boolean indexing to filter values greater than 50 \n",
    "import numpy as np\n",
    "\n",
    "array1 = np.random.randint(1, 101, size=(3, 3, 3))\n",
    "array2 = np.random.randint(1, 101, size=(3, 3, 3))\n",
    "\n",
    "addition_result = np.add(array1, array2)\n",
    "\n",
    "elementwise_mult_result = np.multiply(array1, array2)\n",
    "\n",
    "matrix_mult_result = np.matmul(array1, array2)\n",
    "\n",
    "filtered_values = array1[array1 > 50]\n",
    "\n",
    "print(\"--- Array 1 ---\")\n",
    "print(array1)\n",
    "print(\"\\n--- Matrix Multiplication Result ---\")\n",
    "print(matrix_mult_result)\n",
    "print(\"\\n--- Values > 50 in Array 1 ---\")\n",
    "print(filtered_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c66a1ee-98b0-4fbf-ae90-4964d037e403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of zeros (5x5): \n",
      "  [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "Array of ones (3x4) :\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "Identity matrix (4x4) :\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Array with values from 0 to 50 with step of 5 using arange :\n",
      " [ 0  5 10 15 20 25 30 35 40 45 50]\n",
      "Vertical Concatenation :\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "Horizontal Concatenation :\n",
      " [[1 2 5 6]\n",
      " [3 4 7 8]]\n",
      "Stacked :\n",
      " [[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "# Q14: Create NumPy arrays using special values: \n",
    "# - Array of zeros (5x5) \n",
    "# - Array of ones (3x4) \n",
    "# - Identity matrix (4x4) \n",
    "# - Array with values from 0 to 50 with step of 5 using arange \n",
    "# Concatenate and stack these arrays \n",
    "\n",
    "zeros_5x5 = np.zeros((5, 5))\n",
    "ones_3x4 = np.ones((3, 4))\n",
    "identity_4x4 = np.eye(4)  # np.eye creates the Identity Matrix\n",
    "range_array = np.arange(0, 51, 5) # [0, 5, 10 ... 50]\n",
    "\n",
    "arr_a = np.array([[1, 2], [3, 4]])\n",
    "arr_b = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "concat_v = np.concatenate((arr_a, arr_b), axis=0) # Vertical join\n",
    "concat_h = np.concatenate((arr_a, arr_b), axis=1) # Horizontal join\n",
    "\n",
    "stacked = np.stack((arr_a, arr_b))\n",
    "print(\"Array of zeros (5x5): \\n \", zeros_5x5)\n",
    "print(\"Array of ones (3x4) :\\n\", ones_3x4)\n",
    "print(\"Identity matrix (4x4) :\\n\", identity_4x4)\n",
    "print(\"Array with values from 0 to 50 with step of 5 using arange :\\n\", range_array)\n",
    "print(\"Vertical Concatenation :\\n\", concat_v)\n",
    "print(\"Horizontal Concatenation :\\n\", concat_h)\n",
    "print(\"Stacked :\\n\", stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "391a28d9-5619-4061-a2f2-c9b8ae68a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows from the Quantity-Price 2D array : [[1000.  600.]\n",
      " [1500.  600.]\n",
      " [1000.  600.]]\n",
      "Every alternate element from the Price array  : [600. 600. 600. 600. 600. 600. 600. 600. 600. 600. 700. 600. 600. 700.\n",
      " 600. 600. 600. 600. 600. 600. 700. 700. 600. 600. 600. 600. 700. 600.\n",
      " 600. 600. 500. 600. 600. 600. 500. 700. 600. 750. 700. 600. 650. 600.\n",
      " 500. 650. 600. 500. 500. 600. 500. 600. 550. 750. 600. 700. 600. 500.\n",
      " 750. 700. 300. 550. 700. 600. 600. 650. 700. 700. 500. 600. 750. 600.\n",
      " 750. 550. 650. 600. 750.]\n",
      "Diagonal elements from a 5x5 matrix of TotalAmount values   : [ 600.  600. 2400.  600. 1200.]\n"
     ]
    }
   ],
   "source": [
    "# Q15: Use array slicing to extract: \n",
    "# - First 3 rows from the Quantity-Price 2D array \n",
    "# - Every alternate element from the Price array \n",
    "# - Diagonal elements from a 5x5 matrix of TotalAmount values \n",
    "total_amount_arr = np.array(df['TotalAmount'].head(25))\n",
    "total_amount_arr_5x5 = total_amount_arr.reshape(5,5)\n",
    "\n",
    "\n",
    "\n",
    "first_three_rows = combined_arr[:3, :]\n",
    "print(\"First 3 rows from the Quantity-Price 2D array :\",first_three_rows)\n",
    "\n",
    "alternate_prices = price_arr[::2]\n",
    "print(\"Every alternate element from the Price array  :\",alternate_prices)\n",
    "\n",
    "diagonal_elements = np.diag(total_amount_arr_5x5)\n",
    "print(\"Diagonal elements from a 5x5 matrix of TotalAmount values   :\",diagonal_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abab7c-2985-4853-b68c-b95cf320bca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
